{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/nlp/conf\n",
      "Project name: nlp-nschenone\n",
      "Artifacts path: /User/nlp/jobs\n",
      "MLRun DB path: http://mlrun-api:8080\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path, getenv\n",
    "from mlrun import new_project\n",
    "import nuclio\n",
    "\n",
    "project_name = '-'.join(filter(None, ['nlp', getenv('V3IO_USERNAME', None)]))\n",
    "project_path = path.abspath('conf')\n",
    "project = new_project(project_name, project_path, init_git=True)\n",
    "\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')\n",
    "\n",
    "from mlrun import run_local, NewTask, mlconf, import_function, mount_v3io\n",
    "\n",
    "# Target location for storing pipeline artifacts\n",
    "artifact_path = path.abspath('jobs')\n",
    "# MLRun DB path or API service URL\n",
    "mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "\n",
    "print(f'Artifacts path: {artifact_path}\\nMLRun DB path: {mlconf.dbpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fb24fa97f28>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function('../components/yaml/get_data.yaml', 'get-data')\n",
    "project.set_function('../components/yaml/create_data_bunches.yaml', 'create-data-bunches')\n",
    "project.set_function('../components/yaml/hyper_lm.yaml', 'hyper-lm')\n",
    "project.set_function('../components/yaml/train_lm.yaml', 'train-lm')\n",
    "project.set_function('../components/yaml/hyper_clas.yaml', 'hyper-clas')\n",
    "project.set_function('../components/yaml/train_clas.yaml', 'train-clas')\n",
    "project.set_function('../components/yaml/model_server.yaml', 'model-server')\n",
    "project.set_function('../components/yaml/model_server_tester.yaml', 'model-server-tester')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /User/nlp/conf/workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {path.join(project_path, 'workflow.py')}\n",
    "\n",
    "from kfp import dsl\n",
    "from mlrun import mount_v3io\n",
    "\n",
    "funcs = {}\n",
    "\n",
    "# Configure function resources and local settings\n",
    "def init_functions(functions: dict, project=None, secrets=None):\n",
    "    for f in functions.values():\n",
    "        f.apply(mount_v3io())\n",
    "\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(\n",
    "    name=\"Medical NLP Chemical Classification\",\n",
    "    description=\"Test Pipeline.\"\n",
    ")\n",
    "def kfpipeline(data_size=50000,\n",
    "               split=0.5,\n",
    "               hyper_lm_bs=[64, 128, 256],\n",
    "               hyper_lm_drop_mult=[0.3, 0.6],\n",
    "               hyper_lm_epochs=1,\n",
    "               train_lm_epochs=10,\n",
    "               hyper_clas_bs=[64, 128, 256],\n",
    "               hyper_clas_thresh=[0.01],\n",
    "               hyper_clas_drop_mult=[0.3, 0.6],\n",
    "               hyper_clas_epochs=1,\n",
    "               train_clas_epochs=10,\n",
    "               model_endpoint_name=\"FASTAI_NLP\",\n",
    "               num_preds=8,\n",
    "               num_tests=50):\n",
    "    \n",
    "    # Custom docker image with mlrun and fastai\n",
    "    image = \"docker-registry.default-tenant.app.groupwaretech.iguazio-c0.com:80/fastai\"\n",
    "\n",
    "    # Ingest the data set\n",
    "    ingest = funcs['get-data'].as_step(\n",
    "        name=\"get-data\",\n",
    "        handler='get_data',\n",
    "        inputs={'data_size': data_size},\n",
    "        outputs=['data'])\n",
    "    \n",
    "    # Create data bunches\n",
    "    bunches = funcs['create-data-bunches'].as_step(\n",
    "        name=\"create-data-bunches\",\n",
    "        handler='create_data_bunches',\n",
    "        inputs={'data_path': ingest.outputs['data'], 'split' : split},\n",
    "        outputs=['data_lm', 'data_clas'],\n",
    "        image=image)\n",
    "    \n",
    "    # Language model Hyperparameters\n",
    "    hyperparams = {\"bs\" : hyper_lm_bs,\n",
    "                   \"drop_mult\" : hyper_lm_drop_mult}\n",
    "    \n",
    "    params = {\"epochs\" : hyper_lm_epochs,\n",
    "              \"num_samples\" : data_size,\n",
    "              \"data_lm_path\" : bunches.outputs['data_lm']}\n",
    "    \n",
    "    # Language model Hyperparameter tuning\n",
    "    hyper_tune_lm = funcs['hyper-lm'].as_step(\n",
    "        name=\"hyper-lm\",\n",
    "        handler='train_lm_model',\n",
    "        params=params,\n",
    "        hyperparams=hyperparams,\n",
    "        selector='max.accuracy',\n",
    "        outputs=['best_params'],\n",
    "        image=image)\n",
    "    \n",
    "    # Language model training\n",
    "    train_lm = funcs['train-lm'].as_step(\n",
    "        name=\"train-lm\",\n",
    "        handler='train_lm',\n",
    "        inputs={'train_lm_epochs': train_lm_epochs,\n",
    "                'data_lm_path' : bunches.outputs['data_lm'],\n",
    "                'num_samples' : data_size,\n",
    "                'hyper_lm_best_params_path' : hyper_tune_lm.outputs['best_params']},\n",
    "        outputs=['train_lm_model', 'train_lm_model_enc', 'train_lm_accuracy'],\n",
    "        image=image)\n",
    "    \n",
    "    # Classification model Hyperparameters\n",
    "    hyperparams = {\"bs\" : hyper_clas_bs,\n",
    "                   \"thresh\" : hyper_clas_thresh,\n",
    "                   \"drop_mult\" : hyper_clas_drop_mult}\n",
    "    \n",
    "    params = {\"epochs\" : hyper_clas_epochs,\n",
    "              \"num_samples\" : data_size,\n",
    "              \"encodings\" : train_lm.outputs['train_lm_model_enc'],\n",
    "              \"data_clas_path\" : bunches.outputs['data_clas']}\n",
    "    \n",
    "    # Classification model Hyperparameter tuning\n",
    "    hyper_tune_clas = funcs['hyper-clas'].as_step(\n",
    "        name=\"hyper-clas\",\n",
    "        handler='train_clas_model',\n",
    "        params=params,\n",
    "        hyperparams=hyperparams,\n",
    "        selector='max.fbeta',\n",
    "        outputs=['best_params'],\n",
    "        image=image)\n",
    "    \n",
    "    # Classification model training\n",
    "    train_clas = funcs['train-clas'].as_step(\n",
    "        name=\"train-clas\",\n",
    "        handler='train_clas',\n",
    "        inputs={'train_clas_epochs': train_clas_epochs,\n",
    "                'data_clas_path' : bunches.outputs['data_clas'],\n",
    "                'num_samples' : data_size,\n",
    "                'encodings' : train_lm.outputs['train_lm_model_enc'],\n",
    "                'hyper_clas_best_params_path' : hyper_tune_clas.outputs['best_params']},\n",
    "        outputs=['train_clas_model', 'train_clas_fbeta'],\n",
    "        image=image)\n",
    "\n",
    "    # Serve model\n",
    "    deploy = funcs['model-server'].deploy_step(env={'DATA_CLAS_PATH' : bunches.outputs['data_clas'],\n",
    "                                                   'MODEL_PATH' : train_clas.outputs['train_clas_model'],\n",
    "                                                   f'SERVING_MODEL_{model_endpoint_name}': train_clas.outputs['train_clas_model'],\n",
    "                                                   'NUM_PREDS' : num_preds})\n",
    "\n",
    "    # Model serving tester\n",
    "    tester = funcs['model-server-tester'].as_step(\n",
    "        name='model-tester',\n",
    "        inputs={'model_endpoint': deploy.outputs['endpoint'],\n",
    "                'model_name' : model_endpoint_name,\n",
    "                'data_size' : data_size,\n",
    "                'data_path' : ingest.outputs['data'],\n",
    "                'num_tests' : num_tests})\n",
    "    \n",
    "    \n",
    "#     # TEST MODEL SERVER\n",
    "#     # Serve model\n",
    "#     deploy = funcs['model-server'].deploy_step(env={'DATA_CLAS_PATH' : \"/User/nlp/run/data_clas.pkl\",\n",
    "#                                                    'MODEL_PATH' : \"/User/nlp/run/train_clas_model\",\n",
    "#                                                    f'SERVING_MODEL_{model_endpoint_name}': \"/User/nlp/run/train_clas_model\",\n",
    "#                                                    'NUM_PREDS' : num_preds})\n",
    "\n",
    "#     # Model serving tester\n",
    "#     tester = funcs['model-server-tester'].as_step(\n",
    "#         name='model-tester',\n",
    "#         inputs={'model_endpoint': deploy.outputs['endpoint'],\n",
    "#                 'model_name' : model_endpoint_name,\n",
    "#                 'data_size' : data_size,\n",
    "#                 'data_path' : \"/User/nlp/run/data.pkl\",\n",
    "#                 'num_tests' : num_tests})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'workflow.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-08-13 17:30:19,205 [info] using in-cluster config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"50000\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Float\" based on the value \"0.5\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[64, 128, 256]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[0.3, 0.6]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"1\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"10\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"JsonArray\" based on the value \"[0.01]\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"8\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n",
      "/conda/lib/python3.6/site-packages/kfp/components/_data_passing.py:168: UserWarning: Missing type name was inferred as \"Integer\" based on the value \"50\".\n",
      "  warnings.warn('Missing type name was inferred as \"{}\" based on the value \"{}\".'.format(type_name, str(value)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"https://dashboard.default-tenant.app.groupwaretech.iguazio-c0.com/pipelines/#/experiments/details/0a0575a3-1e49-4018-9a00-227ff947c98f\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"https://dashboard.default-tenant.app.groupwaretech.iguazio-c0.com/pipelines/#/runs/details/9bc8ca5d-c9ef-49c5-b181-45956a07671c\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-08-13 17:30:20,021 [info] Pipeline run id=9bc8ca5d-c9ef-49c5-b181-45956a07671c, check UI or DB for progress\n"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={}, \n",
    "    artifact_path=path.abspath(path.join('pipeline','{{workflow.uid}}')), \n",
    "    dirty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dictlist {\n",
       "  background-color: #b3edff;\n",
       "  text-align: center;\n",
       "  margin: 4px;\n",
       "  border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;}\n",
       ".artifact {\n",
       "  cursor: pointer;\n",
       "  background-color: #ffe6cc;\n",
       "  text-align: left;\n",
       "  margin: 4px; border-radius: 3px; padding: 0px 3px 1px 3px; display: inline-block;\n",
       "}\n",
       "div.block.hidden {\n",
       "  display: none;\n",
       "}\n",
       ".clickable {\n",
       "  cursor: pointer;\n",
       "}\n",
       ".ellipsis {\n",
       "  display: inline-block;\n",
       "  max-width: 60px;\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       ".master-wrapper {\n",
       "  display: flex;\n",
       "  flex-flow: row nowrap;\n",
       "  justify-content: flex-start;\n",
       "  align-items: stretch;\n",
       "}\n",
       ".master-tbl {\n",
       "  flex: 3\n",
       "}\n",
       ".master-wrapper > div {\n",
       "  margin: 4px;\n",
       "  padding: 10px;\n",
       "}\n",
       "iframe.fileview {\n",
       "  border: 0 none;\n",
       "  height: 100%;\n",
       "  width: 100%;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       ".pane-header-title {\n",
       "  width: 80%;\n",
       "  font-weight: 500;\n",
       "}\n",
       ".pane-header {\n",
       "  line-height: 1;\n",
       "  background-color: #ffe6cc;\n",
       "  padding: 3px;\n",
       "}\n",
       ".pane-header .close {\n",
       "  font-size: 20px;\n",
       "  font-weight: 700;\n",
       "  float: right;\n",
       "  margin-top: -5px;\n",
       "}\n",
       ".master-wrapper .right-pane {\n",
       "  border: 1px inset silver;\n",
       "  width: 40%;\n",
       "  min-height: 300px;\n",
       "  flex: 3\n",
       "  min-width: 500px;\n",
       "}\n",
       ".master-wrapper * {\n",
       "  box-sizing: border-box;\n",
       "}\n",
       "</style><script>\n",
       "function copyToClipboard(fld) {\n",
       "    if (document.queryCommandSupported && document.queryCommandSupported('copy')) {\n",
       "        var textarea = document.createElement('textarea');\n",
       "        textarea.textContent = fld.innerHTML;\n",
       "        textarea.style.position = 'fixed';\n",
       "        document.body.appendChild(textarea);\n",
       "        textarea.select();\n",
       "\n",
       "        try {\n",
       "            return document.execCommand('copy'); // Security exception may be thrown by some browsers.\n",
       "        } catch (ex) {\n",
       "\n",
       "        } finally {\n",
       "            document.body.removeChild(textarea);\n",
       "        }\n",
       "    }\n",
       "}\n",
       "function expandPanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName');\n",
       "  console.log(el.title);\n",
       "\n",
       "  document.querySelector(panelName + \"-title\").innerHTML = el.title\n",
       "  iframe = document.querySelector(panelName + \"-body\");\n",
       "\n",
       "  const tblcss = `<style> body { font-family: Arial, Helvetica, sans-serif;}\n",
       "    #csv { margin-bottom: 15px; }\n",
       "    #csv table { border-collapse: collapse;}\n",
       "    #csv table td { padding: 4px 8px; border: 1px solid silver;} </style>`;\n",
       "\n",
       "  function csvToHtmlTable(str) {\n",
       "    return '<div id=\"csv\"><table><tr><td>' +  str.replace(/[\\n\\r]+$/g, '').replace(/[\\n\\r]+/g, '</td></tr><tr><td>')\n",
       "      .replace(/,/g, '</td><td>') + '</td></tr></table></div>';\n",
       "  }\n",
       "\n",
       "  function reqListener () {\n",
       "    if (el.title.endsWith(\".csv\")) {\n",
       "      iframe.setAttribute(\"srcdoc\", tblcss + csvToHtmlTable(this.responseText));\n",
       "    } else {\n",
       "      iframe.setAttribute(\"srcdoc\", this.responseText);\n",
       "    }\n",
       "    console.log(this.responseText);\n",
       "  }\n",
       "\n",
       "  const oReq = new XMLHttpRequest();\n",
       "  oReq.addEventListener(\"load\", reqListener);\n",
       "  oReq.open(\"GET\", el.title);\n",
       "  oReq.send();\n",
       "\n",
       "\n",
       "  //iframe.src = el.title;\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.remove(\"hidden\");\n",
       "  }\n",
       "}\n",
       "function closePanel(el) {\n",
       "  const panelName = \"#\" + el.getAttribute('paneName')\n",
       "  const resultPane = document.querySelector(panelName + \"-pane\");\n",
       "  if (!resultPane.classList.contains(\"hidden\")) {\n",
       "    resultPane.classList.add(\"hidden\");\n",
       "  }\n",
       "}\n",
       "\n",
       "</script>\n",
       "<div class=\"master-wrapper\">\n",
       "  <div class=\"block master-tbl\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>project</th>\n",
       "      <th>uid</th>\n",
       "      <th>iter</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>labels</th>\n",
       "      <th>inputs</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "      <th>artifacts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>\n",
       "  <div id=\"resultfb2bdc1b-pane\" class=\"right-pane block hidden\">\n",
       "    <div class=\"pane-header\">\n",
       "      <span id=\"resultfb2bdc1b-title\" class=\"pane-header-title\">Title</span>\n",
       "      <span onclick=\"closePanel(this)\" paneName=\"resultfb2bdc1b\" class=\"close clickable\">&times;</span>\n",
       "    </div>\n",
       "    <iframe class=\"fileview\" id=\"resultfb2bdc1b-body\"></iframe>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlrun import get_run_db\n",
    "db = get_run_db().connect()\n",
    "db.list_runs(project=project.name, labels=f'workflow={run_id}').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

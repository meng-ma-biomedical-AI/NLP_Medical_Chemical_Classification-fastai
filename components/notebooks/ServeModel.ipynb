{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: ignore\n",
    "import nuclio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%nuclio: setting kind to 'nuclio:serving'\n",
      "%nuclio: setting 'MODEL_CLASS' environment variable\n",
      "%nuclio: setting spec.build.baseImage to 'docker-registry.default-tenant.app.groupwaretech.iguazio-c0.com:80/fastai'\n"
     ]
    }
   ],
   "source": [
    "%nuclio config kind=\"nuclio:serving\"\n",
    "%nuclio env MODEL_CLASS=ClassifierModel\n",
    "%nuclio config spec.build.baseImage = \"docker-registry.default-tenant.app.groupwaretech.iguazio-c0.com:80/fastai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%nuclio cmd -c\n",
    "python -m pip install numpy cloudpickle v3io sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import environ\n",
    "from cloudpickle import load\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "import mlrun\n",
    "import fastai\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModel(mlrun.runtimes.MLModelServer):\n",
    "    def __init__(self, name: str, model_dir: str):\n",
    "        super().__init__(name, model_dir)\n",
    "        self.DATA_CLAS_PATH = environ['DATA_CLAS_PATH']\n",
    "        self.MODEL_PATH = environ['MODEL_PATH']\n",
    "        self.NUM_PREDS = int(environ['NUM_PREDS'])\n",
    "        self.loaded = False\n",
    "            \n",
    "    def load(self):\n",
    "        \"\"\"Bypass loading here due to fastai error (prints pretrained model\n",
    "        to console which mlrun interprets as an error)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load model\"\"\"\n",
    "        self.data_clas = load_data(\"\", self.DATA_CLAS_PATH, bs=32)\n",
    "        self.learn_clas = text_classifier_learner(self.data_clas, AWD_LSTM)\n",
    "        self.model = self.learn_clas.load(self.MODEL_PATH)\n",
    "\n",
    "    def predict(self, body: dict) -> List:\n",
    "        \"\"\"Generate model predictions from sample.\n",
    "        \n",
    "        :param body : A dict of observations, each of which is an 1-dimensional feature vector.\n",
    "            \n",
    "        Returns model predictions as a `List`, one for each row in the `body` input `List`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load model\n",
    "            if not self.loaded:\n",
    "                self.loaded = True\n",
    "                self.load_model()\n",
    "            \n",
    "            # Model prediction\n",
    "            text = body['instances']\n",
    "            pred = self.model.predict(text)\n",
    "            \n",
    "            idxs = []\n",
    "            pred_labels = []\n",
    "            \n",
    "            # Sort predictions by confidence\n",
    "            preds = list(np.argsort(pred[2]))[::-1]\n",
    "            \n",
    "            # Get top predictions\n",
    "            for p in preds[:self.NUM_PREDS]:\n",
    "                idxs.append(p.item())\n",
    "            for idx in idxs:\n",
    "                pred_labels.append(self.data_clas.classes[idx])\n",
    "            \n",
    "            result: np.ndarray = np.asarray(pred_labels)\n",
    "            resp = result.tolist()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Failed to predict {e}\")\n",
    "        \n",
    "        return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclio: end-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2020-08-13 19:02:11,830 [info] function spec saved to path: ../yaml/model_server.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.function.RemoteRuntime at 0x7f8e405010b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlrun import new_model_server\n",
    "fn = new_model_server('model-server', model_class='ClassifierModel', workers=1)\n",
    "fn.spec.description = \"nlp fastai model server\"\n",
    "fn.metadata.categories = ['serving', 'ml']\n",
    "fn.metadata.labels = {'author': 'nschenone'}\n",
    "# fn.set_envs({'INFERENCE_STREAM': 'users/nschenone/tststream'})\n",
    "fn.export(\"../yaml/model_server.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
